\section{Introduction}
Definitions are explicit representations of words or phrases that are valuable
for exposing the aspects of a given term. In general, definitions are
unambiguous and succinct: they should be easy to read and understand. The
qualities of definitions that allow one to directly understand the meaning of a
word or phrase also allow the exploration of the semantic relationships between
words. These qualities have allowed the creation of neural language models that
can generate useful embeddings based on the semantic information contained in
the definitions \cite{hill_learning_2016, bosc_auto_2018}.

Word embeddings have been employed in order to obtain powerful
performance in a variety of NLP tasks. They are useful for capturing lexical
syntax and semantics based on word similarity. \cite{mikolov_distributed_2013}
show that basic mathematical operations applied on word embeddings can show
meaningful language understanding \cite{mikolov_distributed_2013}. However, as
continuous representations, the interpretability of word embeddings is limited.

Thus, the problem of definition modeling was proposed by
\cite{noraset_definition_2016} to evaluate word embeddings
\cite{noraset_definition_2016}. The task of definition modeling is to generate a
definition for a given term. The goal of a model trained on this task is to
train on word embedding and definition pairs in order to learn to generate a
definition for a given word or phrase.

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{assets/defmodel.png}
    \caption{An example of the definition modeling problem for the definiendum
        \textit{free} and an output definition.}
\end{figure}

In addition to being a relatively new language modeling task, definition
modeling has attracted attention from the literature in a number of areas.
First, it was shown that the definition model has poor performance when
generating definitions for polysemes: words with multiple definitions. This
problem was not addressed in the original work as only one definition mapped to
each word. Once researchers attempted to address this problem, they found that
the definition model was unable to learn the semantics of the polyseme with only
the word as an input. Therefore, it was necessary to augment the definition
model with additional information, namely, an example sentence which sets the
word to be defined (\textit{definiendum}) inside to provide context. This method
has been shown to alleviate the problem of generating definitions for polysemes
and also improve the performance of the definition model on several measures
\cite{gadetsky_conditional_2018}, \cite{mickus_mark_2019},
\cite{bevilacqua_generationary_2020}.

Our paper is organized into three sections. Section 2 reviews definition modeling
methods as well as word embeddings used for this task. Section 3 shares benchmark
datasets and statistics that can be used when formulating and evaluating a definition
modeling method. Section 4 explores challenges encountered in this field of research
and gives suggestion for future work.
